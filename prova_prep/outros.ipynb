{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example code that demonstrates how to change the intensity level of a pixel in an image using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define a pixel coordinate (row, col)\n",
    "row = 100\n",
    "col = 150\n",
    "\n",
    "# Define the new intensity level\n",
    "new_intensity = 200\n",
    "\n",
    "# Update the intensity at the specified coordinate\n",
    "image[row, col] = [new_intensity, new_intensity, new_intensity]\n",
    "\n",
    "# Save the modified image\n",
    "cv2.imwrite('modified_image.png', image)\n",
    "\n",
    "print(\"Intensity changed and modified image saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We define a pixel coordinate `(row, col)` where you want to change the intensity.\n",
    "- We define the new intensity level using `new_intensity`.\n",
    "- The intensity of the pixel at the specified coordinate is updated to the new intensity level using array indexing.\n",
    "- The modified image is saved using `cv2.imwrite()` as `'modified_image.png'`.\n",
    "\n",
    "Keep in mind that in this example, we assume the image has color channels (e.g., a color image with RGB channels). If you're working with a grayscale image, you can update the intensity directly without needing to provide multiple values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example code that demonstrates different forms of interpolation using OpenCV. We'll resize an image using various interpolation methods:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define the new dimensions for resizing\n",
    "new_width = 300\n",
    "new_height = 200\n",
    "\n",
    "# Perform different interpolations\n",
    "nearest_neighbor = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_NEAREST)\n",
    "bilinear = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LINEAR)\n",
    "bicubic = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
    "lanczos = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('nearest_neighbor.png', nearest_neighbor)\n",
    "cv2.imwrite('bilinear.png', bilinear)\n",
    "cv2.imwrite('bicubic.png', bicubic)\n",
    "cv2.imwrite('lanczos.png', lanczos)\n",
    "\n",
    "print(\"Images with different interpolation methods saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We define new dimensions for resizing using `new_width` and `new_height`.\n",
    "- We perform resizing using different interpolation methods:\n",
    "  - Nearest Neighbor: `cv2.INTER_NEAREST`\n",
    "  - Bilinear: `cv2.INTER_LINEAR`\n",
    "  - Bicubic: `cv2.INTER_CUBIC`\n",
    "  - Lanczos: `cv2.INTER_LANCZOS4`\n",
    "- The results are saved using `cv2.imwrite()` with filenames indicating the interpolation method used.\n",
    "\n",
    "This code demonstrates how different interpolation methods affect the quality and appearance of resized images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example code that performs the requested operations (addition, subtraction, maximum, and minimum) on an image using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the original image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define another image for the operations\n",
    "other_image = cv2.imread('other_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Perform the operations\n",
    "addition_result = cv2.add(image, other_image)\n",
    "subtraction_result = cv2.subtract(image, other_image)\n",
    "maximum_result = cv2.max(image, other_image)\n",
    "minimum_result = cv2.min(image, other_image)\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('addition_result.png', addition_result)\n",
    "cv2.imwrite('subtraction_result.png', subtraction_result)\n",
    "cv2.imwrite('maximum_result.png', maximum_result)\n",
    "cv2.imwrite('minimum_result.png', minimum_result)\n",
    "\n",
    "print(\"Images with different operations saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` and `'other_image.png'` with the actual paths to the images you want to use.\n",
    "- We read both images using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We perform the requested operations using the following functions:\n",
    "  - Addition: `cv2.add()`\n",
    "  - Subtraction: `cv2.subtract()`\n",
    "  - Maximum: `cv2.max()`\n",
    "  - Minimum: `cv2.min()`\n",
    "- The results are saved using `cv2.imwrite()` with filenames indicating the operation performed.\n",
    "\n",
    "This code demonstrates how to perform basic pixel-wise operations on images using OpenCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example code that demonstrates various bitwise operations on two images using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the original images\n",
    "image1 = cv2.imread('image1.png', cv2.IMREAD_COLOR)\n",
    "image2 = cv2.imread('image2.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Resize the second image to match the dimensions of the first image\n",
    "image2 = cv2.resize(image2, (image1.shape[1], image1.shape[0]))\n",
    "\n",
    "# Perform bitwise operations\n",
    "bitwise_and = cv2.bitwise_and(image1, image2)\n",
    "bitwise_or = cv2.bitwise_or(image1, image2)\n",
    "bitwise_xor = cv2.bitwise_xor(image1, image2)\n",
    "bitwise_not1 = cv2.bitwise_not(image1)\n",
    "bitwise_not2 = cv2.bitwise_not(image2)\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('bitwise_and.png', bitwise_and)\n",
    "cv2.imwrite('bitwise_or.png', bitwise_or)\n",
    "cv2.imwrite('bitwise_xor.png', bitwise_xor)\n",
    "cv2.imwrite('bitwise_not1.png', bitwise_not1)\n",
    "cv2.imwrite('bitwise_not2.png', bitwise_not2)\n",
    "\n",
    "print(\"Images with bitwise operations saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'image1.png'` and `'image2.png'` with the actual paths to the images you want to use.\n",
    "- We read both images using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We resize the second image to match the dimensions of the first image using `cv2.resize()`.\n",
    "- We perform the following bitwise operations using OpenCV functions:\n",
    "  - Bitwise AND: `cv2.bitwise_and()`\n",
    "  - Bitwise OR: `cv2.bitwise_or()`\n",
    "  - Bitwise XOR: `cv2.bitwise_xor()`\n",
    "  - Bitwise NOT: `cv2.bitwise_not()`\n",
    "- The results of each operation are saved using `cv2.imwrite()` with filenames indicating the operation performed.\n",
    "\n",
    "This code demonstrates how to perform various bitwise operations on images using OpenCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Below is an example code that demonstrates various geometric operations using OpenCV, including translation, rotation, scaling, shearing, and perspective transformation:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define the dimensions of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Define translation matrix for x and y\n",
    "translation_matrix = np.float32([[1, 0, 50], [0, 1, 50]])  # Shift by (50, 50)\n",
    "\n",
    "# Define rotation angle in degrees\n",
    "angle = 30\n",
    "rotation_matrix = cv2.getRotationMatrix2D((width/2, height/2), angle, scale=1)\n",
    "\n",
    "# Define scaling factors for x and y\n",
    "scale_x = 1.5\n",
    "scale_y = 0.8\n",
    "scaling_matrix = np.float32([[scale_x, 0, 0], [0, scale_y, 0]])\n",
    "\n",
    "# Define shear parameters\n",
    "shear_x = 0.2\n",
    "shear_y = 0.3\n",
    "shearing_matrix = np.float32([[1, shear_x, 0], [shear_y, 1, 0]])\n",
    "\n",
    "# Define perspective transformation points\n",
    "src_points = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])\n",
    "dst_points = np.float32([[0, 0], [width - 1, 50], [50, height - 1], [width - 51, height - 1]])\n",
    "perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Apply transformations\n",
    "translated_image = cv2.warpAffine(image, translation_matrix, (width, height))\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "scaled_image = cv2.warpAffine(image, scaling_matrix, (width, height))\n",
    "sheared_image = cv2.warpAffine(image, shearing_matrix, (width, height))\n",
    "perspective_image = cv2.warpPerspective(image, perspective_matrix, (width, height))\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('translated_image.png', translated_image)\n",
    "cv2.imwrite('rotated_image.png', rotated_image)\n",
    "cv2.imwrite('scaled_image.png', scaled_image)\n",
    "cv2.imwrite('sheared_image.png', sheared_image)\n",
    "cv2.imwrite('perspective_image.png', perspective_image)\n",
    "\n",
    "print(\"Images with geometric transformations saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We define transformation matrices for various operations, including translation, rotation, scaling, shearing, and perspective transformation.\n",
    "- We apply the transformations using `cv2.warpAffine()` for translation, rotation, scaling, and shearing, and `cv2.warpPerspective()` for perspective transformation.\n",
    "- The results of each transformation are saved using `cv2.imwrite()` with filenames indicating the type of transformation performed.\n",
    "\n",
    "This code demonstrates how to apply different geometric operations to an image using OpenCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! You can use the `AffineTransform` and `getAffineTransform` functions for 2D geometric transformations, and the `warpPerspective` function for perspective transformations. Here's an alternative code using these functions:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define the dimensions of the image\n",
    "height, width = image.shape[:2]\n",
    "\n",
    "# Define translation matrix for x and y\n",
    "translation_matrix = np.float32([[1, 0, 50], [0, 1, 50]])  # Shift by (50, 50)\n",
    "\n",
    "# Define rotation center and angle in degrees\n",
    "rotation_center = (width/2, height/2)\n",
    "angle = 30\n",
    "\n",
    "# Define scaling factors for x and y\n",
    "scale_x = 1.5\n",
    "scale_y = 0.8\n",
    "\n",
    "# Define shear parameters\n",
    "shear_x = 0.2\n",
    "shear_y = 0.3\n",
    "\n",
    "# Define perspective transformation points\n",
    "src_points = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])\n",
    "dst_points = np.float32([[0, 0], [width - 1, 50], [50, height - 1], [width - 51, height - 1]])\n",
    "\n",
    "# Define affine transformation matrices\n",
    "rotation_matrix = cv2.getRotationMatrix2D(rotation_center, angle, scale=1)\n",
    "scaling_matrix = np.float32([[scale_x, 0, 0], [0, scale_y, 0]])\n",
    "shearing_matrix = np.float32([[1, shear_x, 0], [shear_y, 1, 0]])\n",
    "perspective_matrix = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "\n",
    "# Apply transformations\n",
    "translated_image = cv2.warpAffine(image, translation_matrix, (width, height))\n",
    "rotated_image = cv2.warpAffine(image, rotation_matrix, (width, height))\n",
    "scaled_image = cv2.warpAffine(image, scaling_matrix, (width, height))\n",
    "sheared_image = cv2.warpAffine(image, shearing_matrix, (width, height))\n",
    "perspective_image = cv2.warpPerspective(image, perspective_matrix, (width, height))\n",
    "\n",
    "# Save the results\n",
    "cv2.imwrite('translated_image.png', translated_image)\n",
    "cv2.imwrite('rotated_image.png', rotated_image)\n",
    "cv2.imwrite('scaled_image.png', scaled_image)\n",
    "cv2.imwrite('sheared_image.png', sheared_image)\n",
    "cv2.imwrite('perspective_image.png', perspective_image)\n",
    "\n",
    "print(\"Images with geometric transformations saved.\")\n",
    "```\n",
    "\n",
    "This code uses the `getRotationMatrix2D` function to create a rotation matrix and the `warpAffine` function for rotation, translation, scaling, and shearing transformations. The `getPerspectiveTransform` function is used for the perspective transformation. The rest of the code structure and explanations remain the same as in the previous example."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's an example code that demonstrates how to adjust the contrast of an image using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_COLOR)\n",
    "\n",
    "# Define the contrast factor\n",
    "contrast_factor = 1.5\n",
    "\n",
    "# Apply contrast adjustment\n",
    "adjusted_image = cv2.convertScaleAbs(image, alpha=contrast_factor, beta=0)\n",
    "\n",
    "# Save the adjusted image\n",
    "cv2.imwrite('adjusted_image.png', adjusted_image)\n",
    "\n",
    "print(\"Image with adjusted contrast saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` with the default color mode (`cv2.IMREAD_COLOR`).\n",
    "- We define the contrast factor using `contrast_factor`. A value greater than 1 increases contrast, while a value less than 1 decreases contrast.\n",
    "- We apply contrast adjustment using the `cv2.convertScaleAbs()` function, which scales the pixel values by the alpha factor and adds the beta offset.\n",
    "- The adjusted image is saved using `cv2.imwrite()` as `'adjusted_image.png'`.\n",
    "\n",
    "This code demonstrates how to change the contrast of an image using OpenCV."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Below are two separate code examples: one for log transformation and another for gamma transformation. I'll also provide explanations for each transformation.\n",
    "\n",
    "### Log Transformation:\n",
    "\n",
    "Log transformation is a type of image enhancement that enhances the details in the darker regions of the image while compressing the higher-intensity regions. It's particularly useful for images with low contrast in the dark regions. The log transformation formula is: `s = c * log(1 + r)`, where `r` is the input pixel value, `s` is the output pixel value, and `c` is a scaling constant.\n",
    "\n",
    "Here's the code for log transformation:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the scaling constant\n",
    "c = 255 / np.log(1 + np.max(image))\n",
    "\n",
    "# Apply log transformation\n",
    "log_transformed_image = c * np.log(1 + image)\n",
    "\n",
    "# Convert to 8-bit unsigned integer format\n",
    "log_transformed_image = log_transformed_image.astype(np.uint8)\n",
    "\n",
    "# Save the log-transformed image\n",
    "cv2.imwrite('log_transformed_image.png', log_transformed_image)\n",
    "\n",
    "print(\"Log-transformed image saved.\")\n",
    "```\n",
    "\n",
    "### Gamma Transformation:\n",
    "\n",
    "Gamma transformation is used to adjust the overall brightness of an image. It's commonly used to correct the display of images on different devices. The gamma transformation formula is: `s = c * r^gamma`, where `r` is the input pixel value, `s` is the output pixel value, `c` is a scaling constant, and `gamma` is the gamma value.\n",
    "\n",
    "Here's the code for gamma transformation:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the gamma value\n",
    "gamma = 1.5\n",
    "\n",
    "# Apply gamma transformation\n",
    "gamma_transformed_image = np.power(image / 255.0, gamma) * 255.0\n",
    "\n",
    "# Convert to 8-bit unsigned integer format\n",
    "gamma_transformed_image = gamma_transformed_image.astype(np.uint8)\n",
    "\n",
    "# Save the gamma-transformed image\n",
    "cv2.imwrite('gamma_transformed_image.png', gamma_transformed_image)\n",
    "\n",
    "print(\"Gamma-transformed image saved.\")\n",
    "```\n",
    "\n",
    "In both codes:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` in grayscale mode.\n",
    "- We define constants (`c` for log transformation and `gamma` for gamma transformation) to control the scaling.\n",
    "- We apply the respective transformation formulas to each pixel value.\n",
    "- The transformed images are saved using `cv2.imwrite()`.\n",
    "\n",
    "Both log and gamma transformations are non-linear operations that aim to enhance or adjust the appearance of images in different ways. Log transformation enhances the details in dark areas, while gamma transformation adjusts the overall brightness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Contrast stretching is a process that enhances the contrast of an image by stretching the range of pixel values to cover the entire available dynamic range. This technique is especially useful when the image has a narrow range of intensity values, resulting in poor contrast. Contrast stretching can be applied to expand the range of pixel values, making the darker regions darker and the lighter regions lighter.\n",
    "\n",
    "Here's the code for contrast stretching:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the minimum and maximum intensity levels for stretching\n",
    "min_intensity = 50\n",
    "max_intensity = 200\n",
    "\n",
    "# Apply contrast stretching\n",
    "contrast_stretched_image = np.clip((image - min_intensity) * (255 / (max_intensity - min_intensity)), 0, 255)\n",
    "\n",
    "# Convert to 8-bit unsigned integer format\n",
    "contrast_stretched_image = contrast_stretched_image.astype(np.uint8)\n",
    "\n",
    "# Save the contrast-stretched image\n",
    "cv2.imwrite('contrast_stretched_image.png', contrast_stretched_image)\n",
    "\n",
    "print(\"Contrast-stretched image saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- We read an image using `cv2.imread()` in grayscale mode.\n",
    "- We define the minimum and maximum intensity levels (`min_intensity` and `max_intensity`) to determine the desired range of pixel values after stretching.\n",
    "- We apply the contrast stretching formula to each pixel value: `(pixel - min_intensity) * (255 / (max_intensity - min_intensity))`. This maps the original pixel values to the desired range (0 to 255).\n",
    "- The `np.clip()` function ensures that the pixel values stay within the valid range of [0, 255].\n",
    "- The contrast-stretched image is saved using `cv2.imwrite()`.\n",
    "\n",
    "Contrast stretching improves the visual appearance of an image by enhancing the distinction between different intensity levels. It effectively spreads out the intensity values to cover the entire range, leading to better visualization of details and structures in the image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure! Here are two separate code examples: one for histogram matching and another for histogram equalization. I'll also provide explanations for each technique.\n",
    "\n",
    "### Histogram Matching:\n",
    "\n",
    "Histogram matching is a technique used to adjust the histogram of an image to match a specified target histogram. It's useful for transferring the tonal characteristics of one image to another. The basic idea is to transform the pixel values of the input image so that its histogram matches the desired target histogram.\n",
    "\n",
    "Here's the code for histogram matching:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read the source and target images\n",
    "source_image = cv2.imread('source_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "target_image = cv2.imread('target_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute the histograms of the source and target images\n",
    "source_hist, _ = np.histogram(source_image.flatten(), bins=256, range=[0,256])\n",
    "target_hist, _ = np.histogram(target_image.flatten(), bins=256, range=[0,256])\n",
    "\n",
    "# Compute the cumulative distribution functions (CDFs) of the histograms\n",
    "source_cdf = source_hist.cumsum()\n",
    "target_cdf = target_hist.cumsum()\n",
    "\n",
    "# Normalize the CDFs\n",
    "source_cdf_normalized = (source_cdf - source_cdf.min()) / (source_cdf.max() - source_cdf.min())\n",
    "target_cdf_normalized = (target_cdf - target_cdf.min()) / (target_cdf.max() - target_cdf.min())\n",
    "\n",
    "# Initialize the mapping function\n",
    "mapping_function = np.zeros(256)\n",
    "\n",
    "# Perform histogram matching\n",
    "for src_intensity in range(256):\n",
    "    src_difference = np.abs(source_cdf_normalized - src_intensity / 255)\n",
    "    matched_intensity = np.argmin(src_difference)\n",
    "    mapping_function[src_intensity] = matched_intensity\n",
    "\n",
    "# Apply the mapping function to the source image\n",
    "matched_image = mapping_function[source_image]\n",
    "\n",
    "# Convert to 8-bit unsigned integer format\n",
    "matched_image = matched_image.astype(np.uint8)\n",
    "\n",
    "# Save the matched image\n",
    "cv2.imwrite('matched_image.png', matched_image)\n",
    "\n",
    "print(\"Image after histogram matching saved.\")\n",
    "```\n",
    "\n",
    "### Histogram Equalization:\n",
    "\n",
    "Histogram equalization is a method to enhance the contrast of an image by redistributing the pixel intensity values to cover the entire dynamic range. It increases the visibility of details in images with poor contrast. The basic idea is to transform the histogram of an image into a uniform distribution, resulting in a more balanced distribution of pixel values.\n",
    "\n",
    "Here's the code for histogram equalization:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply histogram equalization\n",
    "equalized_image = cv2.equalizeHist(image)\n",
    "\n",
    "# Save the equalized image\n",
    "cv2.imwrite('equalized_image.png', equalized_image)\n",
    "\n",
    "print(\"Equalized image saved.\")\n",
    "```\n",
    "\n",
    "In both code examples:\n",
    "\n",
    "- Replace `'your_image.png'`, `'source_image.png'`, and `'target_image.png'` with the actual paths to the images you want to use.\n",
    "- The code for histogram matching involves computing histograms, cumulative distribution functions (CDFs), and mapping functions to achieve the desired histogram matching effect.\n",
    "- The code for histogram equalization uses `cv2.equalizeHist()` to perform histogram equalization on the input image.\n",
    "\n",
    "Both histogram matching and histogram equalization are techniques for enhancing the contrast and overall appearance of images. They aim to transform the intensity distribution of an image to improve its visual quality and enhance the visibility of details."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einstein\n",
    "\n",
    "Certainly! Below is an example code that generates an image with low, medium, and high contrast using different standard deviations:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def generate_contrast_image(mean, std_deviation):\n",
    "    # Generate a random image with given mean and standard deviation\n",
    "    random_image = np.random.normal(mean, std_deviation, (512, 512))\n",
    "    \n",
    "    # Clip the pixel values to the range [0, 255]\n",
    "    contrast_image = np.clip(random_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return contrast_image\n",
    "\n",
    "# Generate images with different standard deviations\n",
    "low_contrast_image = generate_contrast_image(128, 14)\n",
    "medium_contrast_image = generate_contrast_image(128, 32)\n",
    "high_contrast_image = generate_contrast_image(128, 50)\n",
    "\n",
    "# Save the generated images\n",
    "cv2.imwrite('low_contrast_image.png', low_contrast_image)\n",
    "cv2.imwrite('medium_contrast_image.png', medium_contrast_image)\n",
    "cv2.imwrite('high_contrast_image.png', high_contrast_image)\n",
    "\n",
    "print(\"Images with different contrast levels saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- The function `generate_contrast_image` generates a random image with the given mean and standard deviation, representing different levels of contrast.\n",
    "- The pixel values are then clipped to the range [0, 255] to ensure they are within the valid intensity range for an 8-bit image.\n",
    "- The generated images with low, medium, and high contrast are saved using `cv2.imwrite()`.\n",
    "\n",
    "You can adjust the parameters as needed to achieve the desired contrast levels and appearance for the images."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's the explanation and code for each of the concepts: blurring, blending, and noise reduction in an image.\n",
    "\n",
    "### Blurring:\n",
    "\n",
    "Blurring, also known as smoothing, is a process of reducing the high-frequency noise and details in an image while preserving the overall structure and main features. Blurring can be achieved by applying convolution with a specific filter (kernel) that averages the pixel values in the neighborhood of each pixel. Blurring is often used to reduce noise, remove small details, and prepare images for further processing tasks.\n",
    "\n",
    "Here's an example code that demonstrates blurring using Gaussian blur:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png')\n",
    "\n",
    "# Apply Gaussian blur\n",
    "blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Save the blurred image\n",
    "cv2.imwrite('blurred_image.png', blurred_image)\n",
    "\n",
    "print(\"Blurred image saved.\")\n",
    "```\n",
    "\n",
    "### Blending:\n",
    "\n",
    "Blending involves combining two or more images to create a single composite image. This can be done by adjusting the transparency (alpha) of each image and adding them together. Blending is often used in various applications such as image overlay, creating special effects, and merging images seamlessly.\n",
    "\n",
    "Here's a simple example code that demonstrates blending two images:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read two images\n",
    "image1 = cv2.imread('image1.png')\n",
    "image2 = cv2.imread('image2.png')\n",
    "\n",
    "# Define the blending ratio (alpha value)\n",
    "alpha = 0.5\n",
    "\n",
    "# Perform image blending\n",
    "blended_image = cv2.addWeighted(image1, alpha, image2, 1 - alpha, 0)\n",
    "\n",
    "# Save the blended image\n",
    "cv2.imwrite('blended_image.png', blended_image)\n",
    "\n",
    "print(\"Blended image saved.\")\n",
    "```\n",
    "\n",
    "### Noise Reduction:\n",
    "\n",
    "Noise reduction aims to remove unwanted noise from an image, enhancing the image's clarity and quality. Noise in images can be caused by various factors, such as sensor limitations or environmental conditions. Noise reduction techniques include filtering methods that remove or suppress noise while preserving important image features.\n",
    "\n",
    "Here's an example code that demonstrates noise reduction using a Gaussian filter:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('noisy_image.png')\n",
    "\n",
    "# Apply Gaussian noise reduction\n",
    "denoised_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "\n",
    "# Save the denoised image\n",
    "cv2.imwrite('denoised_image.png', denoised_image)\n",
    "\n",
    "print(\"Denoised image saved.\")\n",
    "```\n",
    "\n",
    "In all of the examples:\n",
    "\n",
    "- Replace `'your_image.png'`, `'image1.png'`, `'image2.png'`, or `'noisy_image.png'` with the actual paths to the images you want to use.\n",
    "- The codes demonstrate basic concepts of blurring, blending, and noise reduction using OpenCV functions. These techniques play important roles in image processing to achieve desired visual effects and improve image quality.\\"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Here's the explanation and code for each of the concepts: Median filter and High-boost filter in an image.\n",
    "\n",
    "### Median Filter:\n",
    "\n",
    "A median filter is a type of spatial filter used for noise reduction in images. It replaces each pixel's value with the median value of the pixel values in its neighborhood. The median filter is effective at reducing impulse noise (salt and pepper noise) and preserving edges in the image. It's especially useful when dealing with highly corrupted images.\n",
    "\n",
    "Here's an example code that demonstrates median filtering using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('noisy_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply median filter\n",
    "filtered_image = cv2.medianBlur(image, 3)  # 3x3 neighborhood window\n",
    "\n",
    "# Save the filtered image\n",
    "cv2.imwrite('filtered_image.png', filtered_image)\n",
    "\n",
    "print(\"Median-filtered image saved.\")\n",
    "```\n",
    "\n",
    "### High-Boost Filter:\n",
    "\n",
    "A high-boost filter is used to enhance the details and edges in an image. It involves the use of a mask to emphasize high-frequency components, such as edges, while suppressing low-frequency components. The basic idea is to subtract a scaled version of the original image from the original image itself. High-boost filtering can improve the overall sharpness and details in the image.\n",
    "\n",
    "Here's an example code that demonstrates high-boost filtering using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Define the scaling factor (A) for high-boost filter\n",
    "scaling_factor = 1.5\n",
    "\n",
    "# Create a Laplacian filter kernel\n",
    "laplacian_kernel = np.array([[0, -1, 0],\n",
    "                             [-1, 4, -1],\n",
    "                             [0, -1, 0]])\n",
    "\n",
    "# Apply the Laplacian filter to the image\n",
    "laplacian_image = cv2.filter2D(image, cv2.CV_32F, laplacian_kernel)\n",
    "\n",
    "# Apply high-boost filtering\n",
    "high_boost_image = image + scaling_factor * laplacian_image\n",
    "\n",
    "# Convert to 8-bit unsigned integer format\n",
    "high_boost_image = np.clip(high_boost_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "# Save the high-boost filtered image\n",
    "cv2.imwrite('high_boost_image.png', high_boost_image)\n",
    "\n",
    "print(\"High-boost filtered image saved.\")\n",
    "```\n",
    "\n",
    "In both examples:\n",
    "\n",
    "- Replace `'noisy_image.png'` or `'your_image.png'` with the actual path to the image you want to use.\n",
    "- The median filter example demonstrates how to apply median filtering using `cv2.medianBlur()`.\n",
    "- The high-boost filter example demonstrates how to perform high-boost filtering by creating a Laplacian kernel and applying it to the image using `cv2.filter2D()`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using gradients for filtering involves using the gradients of an image to create filters that highlight certain features, such as edges or contours. One common approach is to compute the gradient magnitude and direction using techniques like Sobel, Scharr, or Prewitt operators. These gradient values can then be used to create filters that emphasize edges or other structures in the image.\n",
    "\n",
    "Here's an example code that demonstrates using gradients to create a filter that emphasizes edges using the Sobel operator:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Compute the gradient in the x and y directions using the Sobel operator\n",
    "gradient_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Compute the gradient magnitude and direction\n",
    "gradient_magnitude = np.sqrt(gradient_x**2 + gradient_y**2)\n",
    "gradient_direction = np.arctan2(gradient_y, gradient_x)\n",
    "\n",
    "# Create a filter that emphasizes edges using the gradient magnitude\n",
    "edge_filter = gradient_magnitude / np.max(gradient_magnitude)\n",
    "\n",
    "# Apply the edge filter to the image\n",
    "filtered_image = (image * edge_filter).astype(np.uint8)\n",
    "\n",
    "# Save the filtered image\n",
    "cv2.imwrite('filtered_image.png', filtered_image)\n",
    "\n",
    "print(\"Filtered image using gradients saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- The Sobel operators are used to compute the gradients in the x and y directions using `cv2.Sobel()`.\n",
    "- The gradient magnitude and direction are computed using the computed gradient components.\n",
    "- An edge filter is created by normalizing the gradient magnitude values to the range [0, 1].\n",
    "- The image is then filtered by element-wise multiplication with the edge filter to emphasize edges.\n",
    "- The filtered image is saved using `cv2.imwrite()`.\n",
    "\n",
    "Using gradients for filtering can enhance edges and features in an image by highlighting areas with significant intensity changes. This technique is widely used for various computer vision tasks, such as edge detection and feature extraction."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuzzy membership refers to the degree to which a particular element belongs to a specific fuzzy set. Fuzzy logic allows for handling uncertainty and imprecision by assigning membership values between 0 and 1 to elements in a set, indicating the extent to which they belong to that set.\n",
    "\n",
    "Here's an example code that demonstrates how to calculate and visualize fuzzy membership using a simple membership function:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the input range and the membership function parameters\n",
    "x_range = np.linspace(0, 10, 100)\n",
    "mean = 5\n",
    "std_deviation = 2\n",
    "\n",
    "# Calculate the fuzzy membership using a Gaussian membership function\n",
    "fuzzy_membership = np.exp(-0.5 * ((x_range - mean) / std_deviation)**2)\n",
    "\n",
    "# Normalize the membership values to the range [0, 1]\n",
    "fuzzy_membership /= np.max(fuzzy_membership)\n",
    "\n",
    "# Plot the membership function\n",
    "plt.plot(x_range, fuzzy_membership, label='Fuzzy Membership')\n",
    "plt.xlabel('Input')\n",
    "plt.ylabel('Membership Value')\n",
    "plt.title('Fuzzy Membership Function')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- `x_range` represents the range of input values.\n",
    "- `mean` is the center of the membership function.\n",
    "- `std_deviation` controls the spread or width of the membership function.\n",
    "\n",
    "The Gaussian membership function is commonly used due to its smooth and symmetric shape. It assigns higher membership values to elements closer to the center (mean) of the fuzzy set and lower values to those farther away.\n",
    "\n",
    "The plot shows the fuzzy membership values along the input range. The values gradually decrease as you move away from the mean, reflecting the degree of membership of each input to the fuzzy set.\n",
    "\n",
    "Fuzzy membership is a fundamental concept in fuzzy logic and allows for handling gradual transitions and uncertainty in decision-making processes, making it useful in various applications such as control systems, pattern recognition, and artificial intelligence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Let's go through both concepts: separating frequencies in the frequency domain and removing a specific frequency from an image.\n",
    "\n",
    "### Separating Frequencies in the Frequency Domain:\n",
    "\n",
    "Frequency separation involves transforming an image to the frequency domain using the Fourier Transform and then separating its frequency components. High-frequency components represent fine details, edges, and textures, while low-frequency components represent smooth variations and overall structure.\n",
    "\n",
    "Here's an example code that demonstrates how to separate and plot frequency components using the Fourier Transform:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Fourier Transform\n",
    "f_transform = np.fft.fft2(image)\n",
    "f_transform_shifted = np.fft.fftshift(f_transform)\n",
    "\n",
    "# Calculate magnitude spectrum\n",
    "magnitude_spectrum = np.log(np.abs(f_transform_shifted))\n",
    "\n",
    "# Separate and plot the frequency components\n",
    "rows, cols = image.shape\n",
    "crow, ccol = rows // 2, cols // 2\n",
    "\n",
    "# High-pass filter (remove low-frequency components)\n",
    "f_transform_shifted[crow-30:crow+30, ccol-30:ccol+30] = 0\n",
    "\n",
    "# Apply inverse Fourier Transform\n",
    "f_transform_inverse_shifted = np.fft.ifftshift(f_transform_shifted)\n",
    "image_high_pass = np.fft.ifft2(f_transform_inverse_shifted).real\n",
    "\n",
    "# Plot original image and magnitude spectrum\n",
    "plt.subplot(121), plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(122), plt.imshow(image_high_pass, cmap='gray')\n",
    "plt.title('High-Pass Filtered Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- The code applies the Fourier Transform using `np.fft.fft2()` and shifts the zero frequency component to the center using `np.fft.fftshift()`.\n",
    "- It calculates the magnitude spectrum for visualization.\n",
    "- A high-pass filter is applied to remove low-frequency components by setting their values to zero in the frequency domain.\n",
    "- The inverse Fourier Transform is applied using `np.fft.ifft2()` to obtain the high-pass filtered image.\n",
    "- The original image and the high-pass filtered image are plotted side by side for comparison.\n",
    "\n",
    "### Removing a Specific Frequency:\n",
    "\n",
    "Removing a specific frequency from an image involves applying a notch filter to the frequency domain to suppress the corresponding frequency component.\n",
    "\n",
    "Here's an example code that demonstrates how to remove a specific frequency using a notch filter:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Fourier Transform\n",
    "f_transform = np.fft.fft2(image)\n",
    "f_transform_shifted = np.fft.fftshift(f_transform)\n",
    "\n",
    "# Calculate magnitude spectrum\n",
    "magnitude_spectrum = np.log(np.abs(f_transform_shifted))\n",
    "\n",
    "# Create a notch filter to remove a specific frequency\n",
    "notch_filter = np.ones_like(image, dtype=np.float32)\n",
    "crow, ccol = image.shape[0] // 2, image.shape[1] // 2\n",
    "notch_radius = 30\n",
    "notch_filter[crow - notch_radius : crow + notch_radius, ccol - notch_radius : ccol + notch_radius] = 0\n",
    "\n",
    "# Apply the notch filter to the frequency domain\n",
    "f_transform_shifted_filtered = f_transform_shifted * notch_filter\n",
    "\n",
    "# Apply inverse Fourier Transform\n",
    "f_transform_inverse_shifted = np.fft.ifftshift(f_transform_shifted_filtered)\n",
    "image_filtered = np.fft.ifft2(f_transform_inverse_shifted).real\n",
    "\n",
    "# Plot original image, magnitude spectrum, and filtered image\n",
    "plt.subplot(131), plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133), plt.imshow(image_filtered, cmap='gray')\n",
    "plt.title('Filtered Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- A notch filter is created with a hole at a specific frequency (specified by `crow` and `ccol`) to remove that frequency component.\n",
    "- The notch filter is applied to the frequency domain by element-wise multiplication.\n",
    "- The inverse Fourier Transform is applied to obtain the filtered image.\n",
    "- The original image, magnitude spectrum, and filtered image are plotted for comparison.\n",
    "\n",
    "Removing specific frequencies can be useful in scenarios where certain noise frequencies need to be eliminated from an image."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certainly! Let's go through both concepts: Discrete Fourier Transform (DFT) and Aliasing/Antialiasing.\n",
    "\n",
    "### Discrete Fourier Transform (DFT):\n",
    "\n",
    "The Discrete Fourier Transform (DFT) is a mathematical transformation that converts a discrete signal, such as an image, from its spatial domain representation to its frequency domain representation. It decomposes the signal into a sum of sinusoidal components with different frequencies. The DFT is useful for analyzing and manipulating frequency components in images and signals.\n",
    "\n",
    "Here's an example code that demonstrates the DFT and its inverse using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read an image in grayscale\n",
    "image = cv2.imread('your_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply Discrete Fourier Transform\n",
    "dft = np.fft.fft2(image)\n",
    "dft_shifted = np.fft.fftshift(dft)\n",
    "\n",
    "# Calculate magnitude spectrum\n",
    "magnitude_spectrum = np.log(np.abs(dft_shifted))\n",
    "\n",
    "# Apply Inverse Discrete Fourier Transform\n",
    "dft_inverse_shifted = np.fft.ifftshift(dft_shifted)\n",
    "image_reconstructed = np.fft.ifft2(dft_inverse_shifted).real\n",
    "\n",
    "# Plot original image, magnitude spectrum, and reconstructed image\n",
    "plt.subplot(131), plt.imshow(image, cmap='gray')\n",
    "plt.title('Original Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(132), plt.imshow(magnitude_spectrum, cmap='gray')\n",
    "plt.title('Magnitude Spectrum'), plt.xticks([]), plt.yticks([])\n",
    "plt.subplot(133), plt.imshow(image_reconstructed, cmap='gray')\n",
    "plt.title('Reconstructed Image'), plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'your_image.png'` with the actual path to the image you want to use.\n",
    "- The code applies the Discrete Fourier Transform using `np.fft.fft2()` and shifts the zero frequency component to the center using `np.fft.fftshift()`.\n",
    "- It calculates the magnitude spectrum for visualization.\n",
    "- The Inverse Discrete Fourier Transform is applied using `np.fft.ifft2()` to reconstruct the image.\n",
    "\n",
    "### Aliasing and Antialiasing:\n",
    "\n",
    "Aliasing occurs when high-frequency components in an image or signal are mistakenly represented as lower-frequency components, leading to distorted and undesirable effects. Aliasing often manifests as jagged edges or patterns in digital images. Antialiasing is the process of mitigating aliasing effects by reducing high-frequency information before sampling or rendering.\n",
    "\n",
    "Here's an example code that demonstrates aliasing and antialiasing using OpenCV:\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "\n",
    "# Read a high-frequency image\n",
    "high_freq_image = cv2.imread('high_frequency_image.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Downsample the high-frequency image (aliasing)\n",
    "downsampled_image = cv2.resize(high_freq_image, (high_freq_image.shape[1] // 2, high_freq_image.shape[0] // 2))\n",
    "\n",
    "# Save the downsampled image\n",
    "cv2.imwrite('downsampled_image.png', downsampled_image)\n",
    "\n",
    "print(\"Downsampled image (aliasing) saved.\")\n",
    "```\n",
    "\n",
    "In this code:\n",
    "\n",
    "- Replace `'high_frequency_image.png'` with the actual path to the high-frequency image you want to use.\n",
    "- The code downsamples the high-frequency image using `cv2.resize()` to simulate aliasing.\n",
    "- The downsampled image is saved.\n",
    "\n",
    "To remove aliasing, antialiasing techniques can be applied during image acquisition, processing, or rendering. One common approach is to apply a low-pass filter before downsampling to remove high-frequency information beyond the Nyquist frequency. This helps in reducing aliasing effects and preserving the image's visual quality."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
